# Clustering Algorithms Comparative Analysis

A comprehensive research project implementing and comparing multiple clustering algorithms using both synthetic and real datasets. This project provides a systematic evaluation framework for clustering methods including K-Means, Fuzzy C-Means, Gaussian Mixture Models, DBSCAN, and Spectral Clustering.

## ğŸ“Š Research Overview

This project implements a rigorous comparative analysis of clustering algorithms across various scenarios:

- **Synthetic Data Generation**: Using MixSim library for controlled experimental conditions
- **Multiple Clustering Methods**: Implementation of 5 major clustering algorithms
- **Comprehensive Evaluation**: Multiple metrics including Adjusted Rand Index, Silhouette Coefficient, Dunn Index
- **Scalability Analysis**: Performance evaluation across different data dimensions and sizes
- **Visualization**: Comprehensive plotting and statistical analysis

## ğŸ—ï¸ Project Structure

```
clustering-analysis/
â”œâ”€â”€ src/                          # Main source code
â”‚   â””â”€â”€ clustering_analysis/      # Python package
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ algorithms/           # Clustering algorithm implementations
â”‚       â”œâ”€â”€ data_generation/      # Synthetic data generation
â”‚       â”œâ”€â”€ evaluation/           # Metrics and evaluation functions
â”‚       â”œâ”€â”€ visualization/        # Plotting and graphics
â”‚       â””â”€â”€ utils/               # Utility functions
â”œâ”€â”€ data/                        # Data storage
â”‚   â”œâ”€â”€ synthetic/              # Generated synthetic datasets
â”‚   â”œâ”€â”€ real/                   # Real benchmark datasets
â”‚   â””â”€â”€ results/                # Clustering results
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_generation.ipynb
â”‚   â”œâ”€â”€ 02_clustering_analysis.ipynb
â”‚   â””â”€â”€ 03_results_visualization.ipynb
â”œâ”€â”€ scripts/                     # Execution scripts
â”‚   â”œâ”€â”€ run_simulations.py
â”‚   â”œâ”€â”€ generate_data.py
â”‚   â””â”€â”€ create_visualizations.py
â”œâ”€â”€ tests/                       # Unit tests
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ TCC_Document.pdf         # Original thesis document
â”‚   â””â”€â”€ methodology.md           # Detailed methodology
â”œâ”€â”€ config/                      # Configuration files
â”‚   â””â”€â”€ experiment_config.yaml
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Package installation
â””â”€â”€ environment.yml              # Conda environment
```

## ğŸ”¬ Algorithms Implemented

### Partitioning Methods
- **K-Means**: Classic centroid-based clustering
- **Fuzzy C-Means (FCM)**: Soft clustering with membership degrees
- **Gaussian Mixture Models (GMM)**: Probabilistic clustering approach

### Density-Based Methods
- **DBSCAN**: Density-based spatial clustering with noise detection
- **Spectral Clustering**: Graph-based clustering using eigenvalue decomposition

## ğŸ“ˆ Evaluation Metrics

- **Adjusted Rand Index (ARI)**: Measures clustering agreement corrected for chance
- **Rand Index (RI)**: Basic measure of clustering similarity
- **Silhouette Coefficient**: Measures cluster cohesion and separation
- **Dunn Index**: Ratio of minimum inter-cluster to maximum intra-cluster distance
- **Variation of Information (VI)**: Information-theoretic clustering comparison
- **Classification Proportion**: Accuracy of cluster assignments

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd clustering-analysis

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```python
from src.clustering_analysis import ClusteringExperiment

# Initialize experiment
experiment = ClusteringExperiment(config_path='config/experiment_config.yaml')

# Run clustering analysis
results = experiment.run_comparative_analysis(
    bar_omega=0.05,
    n_clusters=3,
    n_dimensions=5,
    n_samples=5000
)

# Generate visualizations
experiment.create_visualizations(results)
```

### Command Line Usage

```bash
# Generate synthetic data
python scripts/generate_data.py --bar-omega 0.05 --clusters 3 --dimensions 5 --samples 5000

# Run clustering algorithms
python scripts/run_simulations.py --config config/experiment_config.yaml

# Create visualizations
python scripts/create_visualizations.py --results-dir data/results/
```

## ğŸ“Š Experimental Design

### Synthetic Data Parameters
- **BarOmega (Ï‰Ì„)**: Overlap measure between clusters (0.0 - 0.6)
- **K**: Number of clusters (2 - 40)
- **P**: Number of dimensions (2 - 200)
- **N**: Number of observations (100 - 2,000,000)

### Real Datasets
- Compound dataset
- Aggregation dataset
- PathBased dataset
- S2 dataset
- Flame dataset
- Face dataset

## ğŸ”§ Dependencies

- **Python**: >= 3.8
- **R**: >= 4.0 (for MixSim simulations and visualizations)
- **Key Libraries**:
  - scikit-learn
  - pandas
  - numpy
  - matplotlib
  - fcmeans
  - MixSim (R)
  - ggplot2 (R)

## ğŸ“ Research Methodology

1. **Data Generation**: Systematic generation of synthetic datasets using MixSim
2. **Algorithm Application**: Implementation of clustering algorithms with parameter optimization
3. **Performance Evaluation**: Multi-metric evaluation including statistical and computational metrics
4. **Comparative Analysis**: Cross-algorithm performance comparison across different scenarios
5. **Visualization**: Comprehensive plotting of results and algorithm behavior

## ğŸ“š Academic References

This project implements methodologies from:
- Statistical clustering analysis literature
- Machine learning comparative studies
- Computational complexity analysis
- Information-theoretic clustering evaluation

## ğŸ¤ Contributing

This is a research project. For academic use, please cite appropriately and follow scientific reproducibility standards.

## ğŸ“„ License

Academic/Research License - Please cite appropriately when using this code.

---

**Note**: This project was developed as part of academic research. The methodology and results should be interpreted within the context of the original research objectives.